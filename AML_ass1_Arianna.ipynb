{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning - programming assignment 1\n",
    "\n",
    "*This assignment will not be graded, but we suggest you finish it before Monday November 24th*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please fill in:**\n",
    "* name 1 (student id 1)\n",
    "* name 2 (student id 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further instructions for assignments:\n",
    "* Code quality is considered during the assessment (of ass 2 & 4). Make sure your code is properly commented. \n",
    "* Submit your code in BrightSpace only for ass 2 & 4.\n",
    "* When you submit the code, make sure to name the submitted file according to your and your collaborators last name (i.e. submitter_collaborator.ipynb). \n",
    "* **Failure to follow these instructions can affect the assignment grade.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-armed Bandits\n",
    "\n",
    "In this programming assignment, we will look at how we can solve a k-armed bandit problem as discussed in the lecture. Expect for winning at the slot machines, you are expect to better understand the tradeoff between exploration and exploiation. \n",
    "\n",
    "Here are the objectives of this assignment:\n",
    "1.   Get familier with the Open-AI gymnasium environment,\n",
    "2.   Implement your own k-armed bandit environment based on the gym framework,\n",
    "3.   Use an epsilon-greedy algorithm to find the optimal action for this k-armed bandit problem,\n",
    "4.   Play with the parameter epsilon and identify a reasonable setting for balancing exploration and exploiation. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Please check the given 'README' file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soq1skOjrr6z"
   },
   "source": [
    "### 1. Let's start with the OpenAI gym\n",
    "\n",
    "Gymnasium (https://gymnasium.farama.org/) is a wide-used toolkit for developing and comparing reinforcement learning algorithms. \n",
    "\n",
    "1. Gymnasium makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano. \n",
    "\n",
    "2. The library is a collection of test problems — **environments** — that you can use to work out your reinforcement learning algorithms. These environments have a shared interface, allowing you to write general algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "on5JDYmWaK-w"
   },
   "source": [
    "**Great!** Now let's import the gymnasium class and work on a basic example of gym code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "5hK-jC9ceDuY"
   },
   "outputs": [],
   "source": [
    "import gymnasium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLePIoe7VJXS"
   },
   "source": [
    "Like mentioned above, gymnasium's main purpose is to provide a large collection of **environments** that expose a common interface. You can find a listing of those environments below (they are Markov decision process(MDP) environments and we discussed MDP in our lecture 2), as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CartPole-v0': EnvSpec(id='CartPole-v0', entry_point='gymnasium.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=0, additional_wrappers=(), vector_entry_point='gymnasium.envs.classic_control.cartpole:CartPoleVectorEnv'), 'CartPole-v1': EnvSpec(id='CartPole-v1', entry_point='gymnasium.envs.classic_control.cartpole:CartPoleEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPole', version=1, additional_wrappers=(), vector_entry_point='gymnasium.envs.classic_control.cartpole:CartPoleVectorEnv'), 'MountainCar-v0': EnvSpec(id='MountainCar-v0', entry_point='gymnasium.envs.classic_control.mountain_car:MountainCarEnv', reward_threshold=-110.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='MountainCar', version=0, additional_wrappers=(), vector_entry_point=None), 'MountainCarContinuous-v0': EnvSpec(id='MountainCarContinuous-v0', entry_point='gymnasium.envs.classic_control.continuous_mountain_car:Continuous_MountainCarEnv', reward_threshold=90.0, nondeterministic=False, max_episode_steps=999, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='MountainCarContinuous', version=0, additional_wrappers=(), vector_entry_point=None), 'Pendulum-v1': EnvSpec(id='Pendulum-v1', entry_point='gymnasium.envs.classic_control.pendulum:PendulumEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pendulum', version=1, additional_wrappers=(), vector_entry_point=None), 'Acrobot-v1': EnvSpec(id='Acrobot-v1', entry_point='gymnasium.envs.classic_control.acrobot:AcrobotEnv', reward_threshold=-100.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Acrobot', version=1, additional_wrappers=(), vector_entry_point=None), 'CartPoleJax-v0': EnvSpec(id='CartPoleJax-v0', entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxEnv', reward_threshold=195.0, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPoleJax', version=0, additional_wrappers=(), vector_entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxVectorEnv'), 'CartPoleJax-v1': EnvSpec(id='CartPoleJax-v1', entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxEnv', reward_threshold=475.0, nondeterministic=False, max_episode_steps=500, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CartPoleJax', version=1, additional_wrappers=(), vector_entry_point='gymnasium.envs.phys2d.cartpole:CartPoleJaxVectorEnv'), 'PendulumJax-v0': EnvSpec(id='PendulumJax-v0', entry_point='gymnasium.envs.phys2d.pendulum:PendulumJaxEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='PendulumJax', version=0, additional_wrappers=(), vector_entry_point='gymnasium.envs.phys2d.pendulum:PendulumJaxVectorEnv'), 'LunarLander-v2': EnvSpec(id='LunarLander-v2', entry_point='gymnasium.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='LunarLander', version=2, additional_wrappers=(), vector_entry_point=None), 'LunarLanderContinuous-v2': EnvSpec(id='LunarLanderContinuous-v2', entry_point='gymnasium.envs.box2d.lunar_lander:LunarLander', reward_threshold=200, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'continuous': True}, namespace=None, name='LunarLanderContinuous', version=2, additional_wrappers=(), vector_entry_point=None), 'BipedalWalker-v3': EnvSpec(id='BipedalWalker-v3', entry_point='gymnasium.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=1600, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='BipedalWalker', version=3, additional_wrappers=(), vector_entry_point=None), 'BipedalWalkerHardcore-v3': EnvSpec(id='BipedalWalkerHardcore-v3', entry_point='gymnasium.envs.box2d.bipedal_walker:BipedalWalker', reward_threshold=300, nondeterministic=False, max_episode_steps=2000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'hardcore': True}, namespace=None, name='BipedalWalkerHardcore', version=3, additional_wrappers=(), vector_entry_point=None), 'CarRacing-v2': EnvSpec(id='CarRacing-v2', entry_point='gymnasium.envs.box2d.car_racing:CarRacing', reward_threshold=900, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CarRacing', version=2, additional_wrappers=(), vector_entry_point=None), 'Blackjack-v1': EnvSpec(id='Blackjack-v1', entry_point='gymnasium.envs.toy_text.blackjack:BlackjackEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'sab': True, 'natural': False}, namespace=None, name='Blackjack', version=1, additional_wrappers=(), vector_entry_point=None), 'FrozenLake-v1': EnvSpec(id='FrozenLake-v1', entry_point='gymnasium.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.7, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'map_name': '4x4'}, namespace=None, name='FrozenLake', version=1, additional_wrappers=(), vector_entry_point=None), 'FrozenLake8x8-v1': EnvSpec(id='FrozenLake8x8-v1', entry_point='gymnasium.envs.toy_text.frozen_lake:FrozenLakeEnv', reward_threshold=0.85, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'map_name': '8x8'}, namespace=None, name='FrozenLake8x8', version=1, additional_wrappers=(), vector_entry_point=None), 'CliffWalking-v0': EnvSpec(id='CliffWalking-v0', entry_point='gymnasium.envs.toy_text.cliffwalking:CliffWalkingEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='CliffWalking', version=0, additional_wrappers=(), vector_entry_point=None), 'Taxi-v3': EnvSpec(id='Taxi-v3', entry_point='gymnasium.envs.toy_text.taxi:TaxiEnv', reward_threshold=8, nondeterministic=False, max_episode_steps=200, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Taxi', version=3, additional_wrappers=(), vector_entry_point=None), 'Jax-Blackjack-v0': EnvSpec(id='Jax-Blackjack-v0', entry_point='gymnasium.envs.tabular.blackjack:BlackJackJaxEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={'sutton_and_barto': True, 'natural': False}, namespace=None, name='Jax-Blackjack', version=0, additional_wrappers=(), vector_entry_point=None), 'Reacher-v2': EnvSpec(id='Reacher-v2', entry_point='gymnasium.envs.mujoco:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Reacher', version=2, additional_wrappers=(), vector_entry_point=None), 'Reacher-v4': EnvSpec(id='Reacher-v4', entry_point='gymnasium.envs.mujoco.reacher_v4:ReacherEnv', reward_threshold=-3.75, nondeterministic=False, max_episode_steps=50, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Reacher', version=4, additional_wrappers=(), vector_entry_point=None), 'Pusher-v2': EnvSpec(id='Pusher-v2', entry_point='gymnasium.envs.mujoco:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pusher', version=2, additional_wrappers=(), vector_entry_point=None), 'Pusher-v4': EnvSpec(id='Pusher-v4', entry_point='gymnasium.envs.mujoco.pusher_v4:PusherEnv', reward_threshold=0.0, nondeterministic=False, max_episode_steps=100, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Pusher', version=4, additional_wrappers=(), vector_entry_point=None), 'InvertedPendulum-v2': EnvSpec(id='InvertedPendulum-v2', entry_point='gymnasium.envs.mujoco:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedPendulum', version=2, additional_wrappers=(), vector_entry_point=None), 'InvertedPendulum-v4': EnvSpec(id='InvertedPendulum-v4', entry_point='gymnasium.envs.mujoco.inverted_pendulum_v4:InvertedPendulumEnv', reward_threshold=950.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedPendulum', version=4, additional_wrappers=(), vector_entry_point=None), 'InvertedDoublePendulum-v2': EnvSpec(id='InvertedDoublePendulum-v2', entry_point='gymnasium.envs.mujoco:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=2, additional_wrappers=(), vector_entry_point=None), 'InvertedDoublePendulum-v4': EnvSpec(id='InvertedDoublePendulum-v4', entry_point='gymnasium.envs.mujoco.inverted_double_pendulum_v4:InvertedDoublePendulumEnv', reward_threshold=9100.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='InvertedDoublePendulum', version=4, additional_wrappers=(), vector_entry_point=None), 'HalfCheetah-v2': EnvSpec(id='HalfCheetah-v2', entry_point='gymnasium.envs.mujoco:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=2, additional_wrappers=(), vector_entry_point=None), 'HalfCheetah-v3': EnvSpec(id='HalfCheetah-v3', entry_point='gymnasium.envs.mujoco.half_cheetah_v3:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=3, additional_wrappers=(), vector_entry_point=None), 'HalfCheetah-v4': EnvSpec(id='HalfCheetah-v4', entry_point='gymnasium.envs.mujoco.half_cheetah_v4:HalfCheetahEnv', reward_threshold=4800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HalfCheetah', version=4, additional_wrappers=(), vector_entry_point=None), 'Hopper-v2': EnvSpec(id='Hopper-v2', entry_point='gymnasium.envs.mujoco:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=2, additional_wrappers=(), vector_entry_point=None), 'Hopper-v3': EnvSpec(id='Hopper-v3', entry_point='gymnasium.envs.mujoco.hopper_v3:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=3, additional_wrappers=(), vector_entry_point=None), 'Hopper-v4': EnvSpec(id='Hopper-v4', entry_point='gymnasium.envs.mujoco.hopper_v4:HopperEnv', reward_threshold=3800.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Hopper', version=4, additional_wrappers=(), vector_entry_point=None), 'Swimmer-v2': EnvSpec(id='Swimmer-v2', entry_point='gymnasium.envs.mujoco:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=2, additional_wrappers=(), vector_entry_point=None), 'Swimmer-v3': EnvSpec(id='Swimmer-v3', entry_point='gymnasium.envs.mujoco.swimmer_v3:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=3, additional_wrappers=(), vector_entry_point=None), 'Swimmer-v4': EnvSpec(id='Swimmer-v4', entry_point='gymnasium.envs.mujoco.swimmer_v4:SwimmerEnv', reward_threshold=360.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Swimmer', version=4, additional_wrappers=(), vector_entry_point=None), 'Walker2d-v2': EnvSpec(id='Walker2d-v2', entry_point='gymnasium.envs.mujoco:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=2, additional_wrappers=(), vector_entry_point=None), 'Walker2d-v3': EnvSpec(id='Walker2d-v3', entry_point='gymnasium.envs.mujoco.walker2d_v3:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=3, additional_wrappers=(), vector_entry_point=None), 'Walker2d-v4': EnvSpec(id='Walker2d-v4', entry_point='gymnasium.envs.mujoco.walker2d_v4:Walker2dEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Walker2d', version=4, additional_wrappers=(), vector_entry_point=None), 'Ant-v2': EnvSpec(id='Ant-v2', entry_point='gymnasium.envs.mujoco:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=2, additional_wrappers=(), vector_entry_point=None), 'Ant-v3': EnvSpec(id='Ant-v3', entry_point='gymnasium.envs.mujoco.ant_v3:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=3, additional_wrappers=(), vector_entry_point=None), 'Ant-v4': EnvSpec(id='Ant-v4', entry_point='gymnasium.envs.mujoco.ant_v4:AntEnv', reward_threshold=6000.0, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Ant', version=4, additional_wrappers=(), vector_entry_point=None), 'Humanoid-v2': EnvSpec(id='Humanoid-v2', entry_point='gymnasium.envs.mujoco:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=2, additional_wrappers=(), vector_entry_point=None), 'Humanoid-v3': EnvSpec(id='Humanoid-v3', entry_point='gymnasium.envs.mujoco.humanoid_v3:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=3, additional_wrappers=(), vector_entry_point=None), 'Humanoid-v4': EnvSpec(id='Humanoid-v4', entry_point='gymnasium.envs.mujoco.humanoid_v4:HumanoidEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='Humanoid', version=4, additional_wrappers=(), vector_entry_point=None), 'HumanoidStandup-v2': EnvSpec(id='HumanoidStandup-v2', entry_point='gymnasium.envs.mujoco:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HumanoidStandup', version=2, additional_wrappers=(), vector_entry_point=None), 'HumanoidStandup-v4': EnvSpec(id='HumanoidStandup-v4', entry_point='gymnasium.envs.mujoco.humanoidstandup_v4:HumanoidStandupEnv', reward_threshold=None, nondeterministic=False, max_episode_steps=1000, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='HumanoidStandup', version=4, additional_wrappers=(), vector_entry_point=None), 'GymV21Environment-v0': EnvSpec(id='GymV21Environment-v0', entry_point=<function _raise_shimmy_error at 0x106d79c60>, reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='GymV21Environment', version=0, additional_wrappers=(), vector_entry_point=None), 'GymV26Environment-v0': EnvSpec(id='GymV26Environment-v0', entry_point=<function _raise_shimmy_error at 0x106d79c60>, reward_threshold=None, nondeterministic=False, max_episode_steps=None, order_enforce=True, autoreset=False, disable_env_checker=False, apply_api_compatibility=False, kwargs={}, namespace=None, name='GymV26Environment', version=0, additional_wrappers=(), vector_entry_point=None)}\n"
     ]
    }
   ],
   "source": [
    "from gymnasium import envs\n",
    "print(envs.registry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to explain how the RL framework of gym works. \n",
    "- An **ENVIRONMENT**, \n",
    "- You also have an **AGENT**,\n",
    "- The agent takes an **ACTION**, in our case, 10 actions are possible to take,\n",
    "- When a single **ACTION** is chosen and fed to our **ENVIRONMENT**, the **ENVIRONMENT** measures how good the action was taken and produces a **REWARD**, which is usually a numeric value.\n",
    "\n",
    "In MDP problems, the **ENVIRONMENT** will also provides an **OBSERVATION**, which represets the state of the **ENVIRONMENT** at the current moment. In the multi-armed bandit problems, there is no **OBSERVATION** (or state) or one constant state. \n",
    "\n",
    "Please read the 'Basic usage' https://gymnasium.farama.org/introduction/basic_usage/ for better understanding the framework. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QA-998XefX85"
   },
   "source": [
    "### 2. Implement your own environment\n",
    "\n",
    "Next, we are going to implement our own environment following the framework of gymnasium. This enviroment is a gambiling room with ten different slot machines (a 10-armed bandit problem). Similar with examples given in the lecture, the reward of each slot machine follows a normal distribution, but the average reward (mean) and variance of each action are different. Your goal is to determine the optimal action from all possible actions/machines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core gym interface is **Env**, which is the unified environment interface. There is no interface for agents. The following are the Env methods you should know:\n",
    "\n",
    "- `step(self, action)`: Steps the environment by one timestep. Returns observation, reward, done, info.\n",
    "- `reset(self)`: Resets the environment to an initial state. Returns an initial observation. Each call of `reset()` should yield an environment suitable for a new episode, independent of previous episodes. Because there is no state transition in multi-armed bandit problems, this function is not used here.\n",
    "- `render(self, mode='human')`: Renders one frame of the environment. The default mode will do something human friendly, such as pop up a window. In this assignment, there is no need to create a pop up window. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before writing your own codes, read through the readme of github page of gymasium (https://github.com/Farama-Foundation/Gymnasium). You are also recommended to read at least the codes for one simple environment and one example agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Self-defined Slot Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please fill in the missing codes in the function sample.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sGDaa_u8fjO3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class slotMachine:\n",
    "    \"\"\"\n",
    "        A slot machine contains a reward distribution that randomly generated with restricted mean and standard deviation. \n",
    "            sample function: generates a reward at each time step based on the given reward distribition\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mu = np.random.uniform(-5, 5)  # mean\n",
    "        self.sigma = np.random.uniform(0.5, 1)  # standard deviation\n",
    "\n",
    "    def sample(self):\n",
    "        return np.random.normal(self.mu, self.sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Game Environment\n",
    "**Please fill in the missing codes in function step in the environment.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces\n",
    "\n",
    "# The environment has to inherit the interface of gymnasium.Env\n",
    "class GamblingRoom(gymnasium.Env):\n",
    "    \"\"\"\n",
    "    A k-armed bandit environment: a gambling room with slot machines, allows the agents to interact with it.\n",
    "        r_machines: A list of slot machines, each gamblingRoom contains k number of slotMachines\n",
    "    \"\"\"\n",
    "    def __init__(self, k, seed=None):\n",
    "        # set random seed\n",
    "        self.seed(seed)     \n",
    "        # initialize reward distribution for each action/machine\n",
    "        self.r_machines = []\n",
    "        for i in range(k):\n",
    "            # each gamblingRoom contains k number of slotMachines\n",
    "            self.r_machines.append(slotMachine())\n",
    "\n",
    "        self.num_arms = k\n",
    "        self.action_space = spaces.Discrete(self.num_arms)\n",
    "        self.observation_space = spaces.Discrete(1)\n",
    "        # for our bandit environment, the state is constant\n",
    "        self.state = 0\n",
    "    \n",
    "    # step up the environment based on the selected action,\n",
    "    # return the constant state, reward, done = false, and info \n",
    "    # for now, we do not have to worry about the DONE and INFO variables.\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        done = False\n",
    "        reward = self.r_machines[action].sample()\n",
    "        \n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    # random seed used for reproducibility purposes\n",
    "    def seed(self, seed):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "    \n",
    "    def reset(self):\n",
    "        pass\n",
    "\n",
    "    def render(self, mode='human', close=False):\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QFSX4fjxrh8"
   },
   "source": [
    "### 3. Implement an agent with the epsilon greedy algorithm\n",
    "\n",
    "In this part, you are expected to implement an RL agent. To decide the action to take at each time step, this agent uses the epsilon greedy algorithm introduced in the lecture.\n",
    "\n",
    "**Please fill in the missing codes in function select_action and update_parameters in the agent.** Feel free to import the needed packages if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NWI9R9BiybZl"
   },
   "outputs": [],
   "source": [
    "class EplisonGreedyAgent:\n",
    "    def __init__(self, k, e):\n",
    "        # set up the number of arms/actions\n",
    "        self.num_arms = k\n",
    "        # set up the value of epsilon\n",
    "        self.epsilon = e\n",
    "        # init the estimated values of all actions\n",
    "        self.Qvalues = np.zeros(k)\n",
    "        # init the numbers of time step that every action is selected\n",
    "        self.stepSize = np.zeros(k)\n",
    "\n",
    "    ##\n",
    "    # select the action to take at the current time step\n",
    "    # (for MDP, choose the action based on state; for k-armed bandit, no state given)\n",
    "    # return: the action to take\n",
    "    ##\n",
    "    def select_action(self):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.num_arms)\n",
    "        else:\n",
    "            return np.argmax(self.Qvalues)\n",
    "\n",
    "    ##\n",
    "    # Update the Q-values of the agent based on received rewards\n",
    "    # input: action_index = the action, reward = the reward from this action\n",
    "    # return: null\n",
    "    ##\n",
    "    def update_parameters(self, action, reward):\n",
    "        self.stepSize[action] += 1\n",
    "        self.Qvalues[action] += (reward - self.Qvalues[action]) / self.stepSize[action]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "me9kN1MPWEEf"
   },
   "source": [
    "### 4. Run the simulation, play with parameters and analyse results\n",
    "\n",
    "Finally, we write codes for running the simulation. \n",
    "\n",
    "In order to decrease the effect of randomness, we usually conduct multiple simulation runs and average the results. In the implementation, you may start with one run, then use the variable `num_runs` for running multiple simulations.\n",
    "\n",
    "In each run, you shall setup the `epsilon` and number of time step `num_episodes` (0.01 and 500 by default). Then, after the initlization of our agent and environment, **please fill in the missing codes (with ??? or TODO: to be filled). **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(10)\n"
     ]
    }
   ],
   "source": [
    "num_action = 10\n",
    "num_seed = 5\n",
    "num_runs = 100  # number of simulation runs\n",
    "num_episodes = 500  # number of steps in each run\n",
    "epsilon = 0.01\n",
    "\n",
    "# init the environment and set up the random seed\n",
    "env = GamblingRoom(num_action, seed = num_seed)\n",
    "\n",
    "# delete the wrap\n",
    "env = env.unwrapped\n",
    "\n",
    "# show the action space\n",
    "print(env.action_space) \n",
    "all_rewards = np.zeros((num_runs, num_episodes))\n",
    "\n",
    "# run multiple simulations\n",
    "for i_run in range(num_runs):\n",
    "    agent = EplisonGreedyAgent(num_action, epsilon)\n",
    "    # state, info = env.reset()\n",
    "    for n in range(num_episodes):\n",
    "        # init the epsilon-greedy RL agent \n",
    "        action = agent.select_action()\n",
    "        state, reward, terminated, info = env.step(action)\n",
    "        agent.update_parameters(action, reward)\n",
    "        # in each simulation run, loop the action selection\n",
    "        # save the result variables you need\n",
    "        all_rewards[i_run, n] = reward\n",
    "    \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgJlSiCGbMBP"
   },
   "source": [
    "Now it's time to examine the performance of algorithms with different epsilon values (different exploration strategies) in multiple simulation runs. \n",
    "\n",
    "You can play with the parameter epsilon under 2 or 3 different gambling environments (by initlizing different reward distributions for machines). **For each environment, you can try different values (e.g. at least 2) of epsilon and identify a reasonable epsilon value that could balance the exploration and exploiation**. It is good to think about how you identify the good epsilon value in this environment and why it is a good one. \n",
    "\n",
    "Few instructions:\n",
    "- Try to generate two plots presenting compariable measures of the different epsilon settings (e.g. the average reward per step and % of optimal action). \n",
    "- You shall present the average results from at least 100 simulation runs. Remember that the gambling environment CANNOT be changed over those runs used for calculating the average results. \n",
    "- You may adjust the total time steps when the learning needs more time for a certain epsilon value, but do not over spend your time on this.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.63149295e+00, -3.88253902e+00, -2.85749513e-01, ...,\n",
       "         1.80428614e+00,  1.97892883e+00,  3.58817694e+00],\n",
       "       [-3.21263187e+00, -2.28789241e+00,  7.32049624e-01, ...,\n",
       "         3.78091685e+00,  2.76357407e+00,  4.02084858e+00],\n",
       "       [-3.18522525e+00, -2.29012443e+00,  9.78873506e-04, ...,\n",
       "         1.83456129e+00,  3.50104739e+00,  2.18351318e+00],\n",
       "       ...,\n",
       "       [-7.06106184e-02, -2.86209084e+00, -7.62655403e-01, ...,\n",
       "         2.97333327e+00,  3.40954748e+00,  4.08294260e+00],\n",
       "       [-3.54406899e+00, -2.16367614e+00, -6.36820004e-01, ...,\n",
       "        -3.83025729e+00,  3.91020153e+00,  3.55757506e+00],\n",
       "       [-1.60766449e+00, -3.73250324e+00,  9.15773017e-01, ...,\n",
       "         2.84013913e+00,  2.81732556e+00,  2.00382917e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_rewards[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'matplotlib.pyplot' from '/Users/arian/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py'>\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m mean_reward \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(all_rewards, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[39m.\u001b[39mplot(mean_reward)\n\u001b[0;32m----> 4\u001b[0m plt\u001b[39m.\u001b[39;49mxlabel(\u001b[39m'\u001b[39;49m\u001b[39mEpisode\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mAverage Reward\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mAvg Reward x Episodes\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "mean_reward = np.mean(all_rewards, axis=0)\n",
    "\n",
    "plt.plot(mean_reward)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel(\"Average Reward\")\n",
    "plt.title('Avg Reward x Episodes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are almost done (and well done)! You do not need to submit this assignment for grading, but it is good to check the solution file. You can ask our TAs during the tutorial sessions if you have any questions. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lesson 1: Multi- Armed Bandit with OpenAi Gym ver 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "73198ca6cdffad3a1cc0aefe30cd1e66b0e97277cf7632e8cb8968b6b9e6582a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
